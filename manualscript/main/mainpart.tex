%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Short Sectioned Assignment
% LaTeX Template
% Version 1.0 (5/5/12)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% Original author:
% Frits Wenneker (http://www.howtotex.com)
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[paper=a4, fontsize=12.5pt]{scrartcl} % A4 paper and 11pt font size
\usepackage[T1]{fontenc} % Use 8-bit encoding that has 256 glyphs
\usepackage{fourier} % Use the Adobe Utopia font for the document - comment this line to return to the LaTeX default
\usepackage[english]{babel} % English language/hyphenation
\usepackage{amsmath,amsfonts,amsthm, bm} % Math packages
\usepackage{multirow}
\usepackage{lipsum} % Used for inserting dummy 'Lorem ipsum' text into the template
\usepackage{graphicx,epstopdf}
\usepackage{url}
\usepackage{color,soul}
\usepackage{sectsty} % Allows customizing section commands
\usepackage{hyperref}
\allsectionsfont{\centering \normalfont\scshape} % Make all sections centered, the default font and small caps

%\usepackage[raggedright]{titlesec} %  LEFT ALIGNMENT OPTION

\usepackage{fancyhdr} % Custom headers and footers
\pagestyle{fancyplain} % Makes all pages in the document conform to the custom headers and footers
\fancyhead{} % No page header - if you want one, create it in the same way as the footers below
\fancyfoot[L]{} % Empty left footer
\fancyfoot[C]{} % Empty center footer
\fancyfoot[R]{\thepage} % Page numbering for right footer
\renewcommand{\headrulewidth}{0pt} % Remove header underlines
\renewcommand{\footrulewidth}{0pt} % Remove footer underlines
\setlength{\headheight}{13.6pt} % Customize the height of the header


\numberwithin{equation}{section} % Number equations within sections (i.e. 1.1, 1.2, 2.1, 2.2 instead of 1, 2, 3, 4)
\numberwithin{figure}{section} % Number figures within sections (i.e. 1.1, 1.2, 2.1, 2.2 instead of 1, 2, 3, 4)
\numberwithin{table}{section} % Number tables within sections (i.e. 1.1, 1.2, 2.1, 2.2 instead of 1, 2, 3, 4)

\setlength\parindent{0pt} % Removes all indentation from paragraphs - comment this line for an assignment with lots of text

% Setup the header and footer
\pagestyle{fancy}                                                       %
%\lhead{ST 565}                                                 %
\chead{Draft}  %
%\rhead{Winter 2014}                                                     %

%\cfoot{}                                                                %
%\rfoot{Page\ \thepage\ of\ \pageref{LastPage}}
%----------------------------------------------------------------------------------------
%	TITLE SECTION
%----------------------------------------------------------------------------------------
\title{Evaluation of Mean and Dispersion of Arabidopsis RNA-Seq Counts Across Different Experiments}
%\author{Xihong Lin}
\date{} % Today's date or a custom date

\begin{document}
\maketitle

\textbf{\href{http://writingcenter.unc.edu/handouts/introductions/}{Tips}}
\begin{enumerate}
\item Start by thinking about the question (or questions) you are trying to answer.
\item Decide how general or broad your opening should be.
\item Try writing your introduction last.
\item Don't be afraid to write a tentative introduction first and then change it later.
\item Open with an attention grabber. 
\item Pay special attention to your first sentence. 
\item Be straightforward and confident.
\end{enumerate}

\section{Introduction}
RNA sequencing (RNA-Seq) has gained {\color{red}{\st{more and more}}} popularity in measuring gene  expression level for the past few years. A variety of experiments  have been conducted in this routine for {\color{red}{\st{all kinds of purpose}}} different purposes, among which one major task is to detect differential expression (DE) genes. Several R packages (e.g., edgeR, DESeq2, NBPSeq)[{\color{green}{reference needed}}] are available to implement DE analysis for RNA-Seq data. The exponential growth of such routine generates a large number of count datasets, making comparison between different experiments possible. 
[from Translational signatures and mRNA...]
Analysis of datasets of stably expressed genes would provide more accurate and reliable measurements of associations between variations of a specific gene characteristic and expression, and how distinct gene features work to optimize gene expression.

It is therefore interesting to ask, for a specific species, whether there is similarity or dissimilarity across experiments. This motivates us to propose several interesting questions. First, whether there are some genes stably expressed despite various experimental conditions; Second, whether there is any commonality between the mean and dispersion across different experiments. We hope by answering these questions, we're able to provide a better perspective to look at normalization issue, as well as modelling approach of mean and dispersion\footnote{we haven't brought up NB distribution yet}. \\


Although statistical models vary from one to another, it is widely assumed that gene counts follow a Negative Binomial (NB) distribution [{\color{green}{reference needed}}]. This assumption has the advantage of capturing both the expression level (mean $\mu$) and biological variation (dispersion parameter $\phi$). The variance of NB distribution depends on the mean in the form of 
\[\text{Var}= \mu +\mu^2\phi\eqno(1.1)\]
where the first term can represent mean expression level and the second term can represent variance due to variation between biological replicates. However, quantifying biological variation has never been an easy task. The major challenge lies in the fact that usually only a small sample size (six for example, with 3 in experimental group and 3 in control group) is available due to the cost of sequencing. More needed.... \\



In this paper, we focus on 20[number of dataset] experiments on \textit{arabidopsis thaliana} conducted by different research groups. For the purpose of identifying stably expressed genes, we fit a negative binomial model with a random term accounting for different experiments effect. We showed that.... In addition, we also found that different experiments share some information about the dispersion parameters. We are able to predict dispersion of one experiment by regressing on dispersion and mean from other experiment datasets. The variance of dispersion which is assumed to be log-normally distributed is also evaluated. We showed further that, modelling approach has the merit of ... in regarding. 

\section{Data Description}
10\footnote{to be determined} \textit{arabidopsis thaliana} data sets are used in this paper.

\section{methods}
Negative binomial regression models are suggested for count data from RNA-Seq experiment{\color{green}{[Reference]}}, to account for over dispersion. However, since  GLM approaches are non-linear and require iterative fitting, a common issue is algorithmic failure for some genes in some datasets. \\

\subsection{Negative binomial regression with random effect}
There are various ways of presenting the negative binomial distribution, and a detailed explanation can be found in Hilbe(2007). It can be viewed as a Poisson-Gamma mixture, which means we assume that $Y$'s are Poisson distributed with mean $\mu$ following a Gamma distribution. The density function is then expressed as
\[f(y; k,\mu)=\frac{\Gamma(y+ k)}{\Gamma(k)\Gamma(y + 1)}\times \left(\frac{k}{\mu + k }\right)^k\times\left(1- \frac{k}{\mu + k }\right)^y\]
where $\Gamma(y+1)=(y+1)!$.\\ The mean and variance of $Y$ are given by
\[E(Y)= \mu  ~~~~~~\text{Var}(Y)=\mu + \frac{\mu^2}{k}\]
Note that by letting $\phi= 1/k$ where $\phi$ is usually recognized as dispersion parameter,  we can reexpress the variance as $\text{Var}(Y)= \mu + \phi\mu^2$. We will stick to this notation from now on.

\textbf{ Basic Setup of NB Regression}\\
The NB regression is set up by three steps
\begin{enumerate}
  \item $Y_i$ is negative binomial distributed with mean $\mu_i$ and dispersion parameter $\phi$.
  \item the predictor is given by $\eta = X\alpha + Zb$, where $\alpha$ and $b$ are fixed and random effects, respectively. In addition, we suppose $b\sim N(0, \sigma^2)$.
  \item there is a link between the mean $Y$ and predictor $\eta = g(\mu)$, by default glmmadmb uses ....
\end{enumerate}

For  \href{http://support.sas.com/documentation/cdl/en/statug/63033/HTML/default
/viewer.htm#statug_nlmixed_sect022.htm}{SAS} \verb"PROC NLMIXED" , the theory behind this procedure \\
\textbf{1. Assumptions and Notations}\\
  The observed data vector $\bm y_i$ for each $I$ subjects, $i=1, \ldots, s$ and $\bm y_i$ are assumed to be independent across $i$, but within-subject covariance is likely to exist because each of the elements of $\bm y_i$ is measured on the same subject( {\color{blue}{that implies it can deal with repeated measurement}}). The joint probability density function 
  \[p(\bm y_i|\bm X_i, \bm \phi, \bm u_i)q(\bm u_i|\bm \xi)\]
  where $\bm X_i$ is a matrix of observed explanatory variables and $\bm \phi, \bm \xi$ are vectors of unknown parameters.\\
  Let $\bm \theta =[\bm \phi, \bm \xi)]$ is of dimension $n$. Then we can make inference about $\bm\theta$ by the marginal likelihood function
  \[m(\bm \theta)= \prod_{i=1}^s\int p(\bm y_i|\bm X_i, \bm \phi, \bm u_i)q(\bm u_i|\bm \xi)d\bm u_i\]. Essentially we obtain $\hat{\bm \theta}$ by minimizing 
  $$f(\bm \theta)= -\log [m(\bm \theta)]$$
 Next we apply the NB regression setup here.
 Let $Y_{ij}$ represents the number of RNA-Seq reads from biological sample $j$ attributed to gene $i$, for $i=1, \ldots, m$; $j=1, \ldots, n$. Let $N_j$ be the total number of genes for a particular biological sample $i$ (i.e., $N_j = \sum_{i=1}^m Y_{ij}$), which is usually referred to as \textit{library sizes} For a particular gene $i$ 
  \[Y_{ij} \sim NB(\mu_{ij}, \phi_{ij}),\] 
  where $\mu_{ij}$ is the mean and $\phi_{ij}$ is the dispersion parameter in the NB2 parametrization.  The link function for the mean
  \[\eta_{ij} = \log(\mu_{ij})= \log(R_jN_j)+\beta_0 + e_{ij}\eqno(a)\]
  or 
  \[\eta_{ij} = \log(\mu_{ij})= \log(R_jN_j)+\beta_0 +\bm Z\bm b\eqno(b)\]
  where $R_j$s are optimal normalization factors, and $e_k\sim N(0, \sigma^2)$ in (a) if we assume a simple random effect , or in the context of covariance structure  
\[\bm b \sim N(0, V)  ~~\text{and} ~~V = 
	\sigma^2\left[
 	\begin{array}{ccc}
 	  1 &\rho_{12} & \rho_{13}\\
 	  \rho_{12} &1 & \rho_{23}\\
 	  \rho_{13} & \rho_{23} &1 \\
\end{array} 		
	\right]	
	\]  
	for a typical experiment of 3 biological sample setting [Not sure if this is exactly right]. If there are multiple labs, $V$ should be a diagonal block matrix, where each block represents a lab experiment. {\color{blue}{ However, glmmADMB only allows "diagonal" or "full" (where all elements are estimated). SAS NLMIXED does provide the option to specify covariance matrix, e.g.  \\
	
	\verb"random b1 b2 b3 ~ normal([0,0,0],[g11,g21,g22,g31,g32,g33])" }}\\
	
{\color{red}Unfortunately, it has convergence issue for a small sample size.} 
%$\bm\pi_{j}=(\pi_{j1}, \pi_{j2}, \ldots, \pi_{kJ})$. $\phi_{k'}$ is the dispersion for the same gene from another group. %{\color{blue}{not sure if normalization is needed yet, in which case we might begin with $\log(\mu_i)= \beta + \log (N_i R_i) + e_i$}}. 
  %The data set I analyze consists of 4 labs of arabidopsis experiment with 2 or 3 samples in each lab. That being said, I am assuming the means for different labs vary only in terms of random effect $e_i$.  {\color{blue} Note: for now we just assume $\phi$ is a constant within different samples for a particular gene.}
  Note that for a particular gene $i$,  $\bm \theta= (\beta_i, \sigma_i^2)$, and
  %and for SAS \verb"PROC NLMIXED" the NB $Y\sim \text{negbin}(n, p)$ log-likelihood is 
 % \[  l(n, p; y)= \log[\Gamma(n+y)]- \log[\Gamma(n)] - \log[\Gamma(y +1)] + n\log(p) + y\log(1-p)\]
 % \[E[Y] = kP = k\left(\frac{1-p}{p}\right), \text{Var}[Y] = kP(1-P) = k \left(\frac{1-p}{p}\right)\frac{1}{p}\] 
%  with $n \geq 0 , 0 <p < 1$. That is equivalent to $\mu = kP, k = 1/\phi$  under NB2 parametrization.  Therefore the $p(\cdot)$ can be written as 
 % \[p(y_i, p, k)= \frac{\Gamma(y+ k)}{\Gamma(k)\Gamma(y + 1)}\times p^k(1-p)^y\]
 $\mu_{ij}= R_jN_je^{\beta_i + e_{ij}}$ we have % = k(1-p)/p$ we have  
 % \[ p =  \frac{1}{k^{-1}e^{\beta  + e_i} + 1}\]
 % Subsequently

\[f(y_{ij}| \beta_i, e_{ij}, \phi_i)\]
\[= \frac{\Gamma(y_{ij}+ \phi_i^{-1})}{\Gamma(\phi_i^{-1})\Gamma(y_{ij} + 1)}\times \left(\frac{1}{\phi_iR_jN_j\exp(\beta_i  + e_{ij}) + 1}\right)^{\phi_i^{-1}}\left(1-\frac{1}{\phi_iR_jN_j\exp(\beta_i  + e_{ij}) + 1}\right)^{y_{ij}}\]


  Now that $e_{ij}\sim N(0, \sigma_i^2)$ with $q(e_{ij}|\sigma_i^2)= \frac{1}{\sqrt{2\pi\sigma_i^2}}\exp\left(-\frac{e_{ij}^2}{2\sigma_i^2}\right)$ gives 
    \[m(\beta_i, \sigma_i^2, \phi_i)=\prod_{j=1}^n\int p(y_{ij}| \beta_i, e_{ij}, \phi_i)q(e_{ij}|\sigma_i^2)de_{ij}\]  
    \[=\prod_{j= 1}^n\int\frac{\Gamma(y_{ij}+ {\phi_i}^{-1})}{\Gamma(\phi_i^{-1})\Gamma(y_{ij} + 1)}\times \left(\frac{1}{\phi_i N_jR_je^{\beta_i  + e_{ij}} + 1}\right)^{\phi_i^{-1}}\left(1-\frac{1}{\phi_i N_jR_je^{\beta_i  + e_{ij}} + 1}\right)^{y_{ij}} \]
    \[\times \frac{1}{\sqrt{2\pi\sigma_i^2}}\exp\left(-\frac{e_{ij}^2}{2\sigma_i^2}\right)de_{ij} \]
  \textbf{2. Integration Approximation}\\
   \verb"PROC NLMIXED" uses \href{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.55.99&rep=rep1&type=pdf}{adaptive Gaussian Quadrature (Pinheiro and Bates 1995)} while R Package \verb"glmmADMB" adopts Laplace Approximation (reference ???). According to SAS documentation, the latter is just a $1^{\text{st}}$ order special case of the former. \\   
   
   For each particular gene $i$, let $p_{i} = p(\beta_i, e_{ij}) =\frac{1}{\phi_i N_jR_je^{\beta_i  + e_{ij}} + 1}$, then rewriting $m(\beta_i, \sigma^2_i, \phi_i)$ gives 
\begin{align*}
  & m(\beta_i, \sigma^2_i, \phi_i) \\
   &= \prod_{j=1}^n\frac{\Gamma(y_{ij}+ \phi_i^{-1})}{\Gamma(\phi_i^{-1})\Gamma(y_{ij} + 1)}\int [p(\beta_i, e_{ij})]^{\phi_i^{-1}}[1-p(\beta_i, e_{ij})]^{y_{ij}}\frac{1}{\sqrt{2\pi\sigma^2_i}}\exp\left(-\frac{e_{ij}^2}{2\sigma_i^2}\right)~de_{ij}  \\
   &= \prod_{j=1}^n\frac{\Gamma(y_{ij}+ \phi_i{-1})}{\Gamma(\phi_i^{-1})\Gamma(y_{ij} + 1)}\int e^{\phi_i^{-1}\log[p(\beta_i,e_{ij})]}e^{y_{ij}\log[1-p(\beta_i, e_{ij})]} \frac{1}{\sqrt{2\pi\sigma_i^2}}\exp\left(-\frac{e_{ij}^2}{2\sigma_i^2}\right)~de_{ij} \\ 
   & =\prod_{j=1}^n\frac{\Gamma(y_{ij}+ \phi_i^{-1})}{\Gamma(\phi_i^{-1})\Gamma(y_{ij} + 1)}\frac{1}{\sqrt{2\pi\sigma^2_i}}\int \exp\left[\phi_i^{-1}\log (p_{i}) + y_{ij}\log(1-p_{i}) - \frac{e_{ij}^2}{2\sigma_i^2}\right]~de_{ij}
\end{align*}
   The integral is approximated by Gaussian Quadrature. Denote
    $$l(e_{ij}, y_{ij})=\phi_i^{-1}\log(p_{i}) + y_{ij}\log(1-p_{i})-\frac{e_{ij}^2}{2\sigma_i^2}$$
   Let $e_{ij}^{\ast}$ maximizes $l(e_{ij}, y_{ij})$., then  $(\ast)$ can be approximated by 
   \[ \text{Gaussian Quadrature here}\]
   Can try
   \begin{verbatim}
   file.show(system.file("tpl","glmmadmb.tpl",package="glmmADMB"))" 
   \end{verbatim}
   to see how parameters are estimated in \verb"glmmADMB".\\
   It seems the \href{http://www.admb-project.org/documentation/manuals}{ADMB-RE} package (implementing random effects in nonlinear models) is also adaptive to non-normally distributed random effects and C++ programs are available. 
   SAS code for NB regression.\\
   
   \textbf{Now Back to Question 1} we wanted to address.  In this regression setting, we obtain a vector of $m$ $\sigma^2$s for a total of $m$ genes. We would expect smaller $\sigma^2$ for genes that are stably expressed. The problem reduces to choose a threshold of $\sigma^2_0$, then genes with $<\sigma^2_0$ will be identified as stably expressed. 
   \subsection{Gamma regression and variance of dispersion}
       In this section, we tried to evaluate dispersion models. The NBQ model[{\color{green}{reference}}] states that dispersion is a quadratic function of the relative mean $\pi_{ij}=\mu_{ij}/(N_jR_j)$
   \[\log(\phi_{ij})= \alpha_0 + \alpha_1\log[\pi_{ij}] + \alpha_2(\log[\pi_{ij}])^2\]
  A natural extension of the model is to add a term quantifying the "noise" for dispersion, that is, the "true" logged dispersion is normally distributed. 
  \begin{verbatim}
  > head(arab)
          mock1 mock2 mock3 hrcc1 hrcc2 hrcc3
AT1G01010    35    77    40    46    64    60
AT1G01020    43    45    32    43    39    49
AT1G01030    16    24    26    27    35    20
AT1G01040    72    43    64    66    25    90
AT1G01050    49    78    90    67    45    60
AT1G01060     0    15     2     0    21     8

> head(pf$estimates)
          [,1]      [,2]      [,3]      [,4]      [,5]      [,6]
[1,] 0.1879878 0.1879878 0.1879878 0.1747160 0.1747160 0.1747160
[2,] 0.2113727 0.2113727 0.2113727 0.2019324 0.2019324 0.2019324
[3,] 0.3121561 0.3121561 0.3121561 0.2513636 0.2513636 0.2513636
[4,] 0.1760997 0.1760997 0.1760997 0.1821039 0.1821039 0.1821039
[5,] 0.1642851 0.1642851 0.1642851 0.1778045 0.1778045 0.1778045
[6,] 0.9426165 0.9426165 0.9426165 0.5257880 0.5257880 0.5257880
  \end{verbatim}
  \[\log(\phi_{ij})= \log(\phi^0_{ij})+ \epsilon_{ij}\]
  where $\phi^0_{ij}$s is obtained by fitting NBQ model $\epsilon_{ij}$ is assumed to be $N(0, \sigma^2)$. \\
  
   Gu has showed that  when $\sigma^2$ is below certain level, parametric based modelling approaches have advantage over non-parametric approaches (e.g. genewise in \verb"edgeR"). The aim of our analysis is to explore possible improvement if additional predictors are incorporated in the parametric dispersion model. Specifically, we tried the following models
   \begin{enumerate}
   \item The true dispersion is a function of relative means, but 
   \[\log(\phi_{ij})= \alpha_0 + \sum_{j=1}^n(\alpha_{l1}\pi_{ij} + \alpha_{l2}[\pi_{jk, l}]^2) + \epsilon_{kj} \]
   \end{enumerate}

   	and 
   	\[\log(\phi_{kj,l'})= \alpha_0 + \sum_{l=1}^L[\alpha_{l1}\pi_{jk, l} + \alpha_{l2}(\pi_{jk, l})^2] + log(\phi_{kj, l''})   	\]
   	where $l', l''\in \{1, 2, \ldots, L\}$ and $L$ is the number of labs available.\\
	Actually we first tried Gamma regression models
	\[\phi_{jk} \sim \text{Gamma}(\mu, \sigma), E[\phi_{jk}]=\mu,  \text{Var}[\phi_{jk}] = \sigma^2\]
	with link function 
	\[\log(\mu)=\beta_0 +\sum_{l=1}^L(\beta_{l1}[\log\pi_{jk, l}] + \beta_{l2}[\log\pi_{jk, l}]^2) + \epsilon\]
	and $\epsilon\sim N(0, \sigma^2)$.
	or adding corresponding dispersions from another dataset
	\[\log(\mu)=\beta_0 +\sum_{l=1}^L(\beta_{l1}[\log\pi_{jk, l}] + \beta_{l2}[\log\pi_{jk, l}]^2) + \log(\phi){jk, l}) + \epsilon\]
  %\begin{verbatim}
  % proc nlmixed;
  %    parms b0=1 b1=0 scale=14; /*initiating parameters*/
  %    linp = b0 + b1*x; /*link function*/
  %    mu   = exp(linp);
  %    b    = mu/scale;
  %    model y ~ gamma(scale,b);
  % run;
  %\end{verbatim}
  \section{results}
  \section{discussion}
  \section{reference}
\end{document}